WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

========== Reacher2Dof-v0 ==========
Seed: 1
OrderedDict([('n_envs', 8),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
Overwriting n_timesteps with n=100000
Creating test environment
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/distributions.py:418: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:198: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:240: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

Log path: logs/train_0.1M_Reacher2Dof-v0/ppo2/Reacher2Dof-v0_2
--------------------------------------
| approxkl           | 0.0009122477  |
| clipfrac           | 0.0024414062  |
| explained_variance | 0.00901       |
| fps                | 1523          |
| n_updates          | 1             |
| policy_entropy     | 2.838486      |
| policy_loss        | -0.0035214433 |
| serial_timesteps   | 128           |
| time_elapsed       | 1.38e-05      |
| total_timesteps    | 1024          |
| value_loss         | 16.401844     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0006128848 |
| clipfrac           | 0.0014648438 |
| ep_len_mean        | 150          |
| ep_reward_mean     | -9.72        |
| explained_variance | 0.0119       |
| fps                | 3779         |
| n_updates          | 2            |
| policy_entropy     | 2.8380258    |
| policy_loss        | -0.001608469 |
| serial_timesteps   | 256          |
| time_elapsed       | 0.672        |
| total_timesteps    | 2048         |
| value_loss         | 20.495958    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0017943262  |
| clipfrac           | 0.015380859   |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.3         |
| explained_variance | 0.00394       |
| fps                | 3780          |
| n_updates          | 3             |
| policy_entropy     | 2.8383226     |
| policy_loss        | -0.0047239996 |
| serial_timesteps   | 384           |
| time_elapsed       | 0.943         |
| total_timesteps    | 3072          |
| value_loss         | 15.898782     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0005510923  |
| clipfrac           | 0.0007324219  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.1         |
| explained_variance | 0.0131        |
| fps                | 3576          |
| n_updates          | 4             |
| policy_entropy     | 2.840036      |
| policy_loss        | -0.0016712062 |
| serial_timesteps   | 512           |
| time_elapsed       | 1.21          |
| total_timesteps    | 4096          |
| value_loss         | 15.920757     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00047079573 |
| clipfrac           | 0.0012207031  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -9.87         |
| explained_variance | 0.0371        |
| fps                | 3686          |
| n_updates          | 5             |
| policy_entropy     | 2.8412166     |
| policy_loss        | -0.0011908062 |
| serial_timesteps   | 640           |
| time_elapsed       | 1.5           |
| total_timesteps    | 5120          |
| value_loss         | 13.9712715    |
--------------------------------------
--------------------------------------
| approxkl           | 0.0006299508  |
| clipfrac           | 0.0026855469  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.9         |
| explained_variance | -0.00755      |
| fps                | 3841          |
| n_updates          | 6             |
| policy_entropy     | 2.8414876     |
| policy_loss        | -0.0025463481 |
| serial_timesteps   | 768           |
| time_elapsed       | 1.78          |
| total_timesteps    | 6144          |
| value_loss         | 14.933539     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00032367226 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.9         |
| explained_variance | 0.0179        |
| fps                | 3934          |
| n_updates          | 7             |
| policy_entropy     | 2.842044      |
| policy_loss        | -0.0008112921 |
| serial_timesteps   | 896           |
| time_elapsed       | 2.05          |
| total_timesteps    | 7168          |
| value_loss         | 18.55405      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00021046816 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.8         |
| explained_variance | -0.00302      |
| fps                | 3798          |
| n_updates          | 8             |
| policy_entropy     | 2.8427856     |
| policy_loss        | -0.0014974949 |
| serial_timesteps   | 1024          |
| time_elapsed       | 2.31          |
| total_timesteps    | 8192          |
| value_loss         | 13.751711     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00022223483 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -12.1         |
| explained_variance | -0.0334       |
| fps                | 3763          |
| n_updates          | 9             |
| policy_entropy     | 2.8424602     |
| policy_loss        | -0.0010054116 |
| serial_timesteps   | 1152          |
| time_elapsed       | 2.58          |
| total_timesteps    | 9216          |
| value_loss         | 17.707405     |
--------------------------------------
Eval num_timesteps=10000, episode_reward=-4.12 +/- 4.55
Episode length: 150.00 +/- 0.00
New best mean reward!
--------------------------------------
| approxkl           | 0.00028185517 |
| clipfrac           | 0.00024414062 |
| ep_len_mean        | 150           |
| ep_reward_mean     | -12.4         |
| explained_variance | 0.00923       |
| fps                | 1373          |
| n_updates          | 10            |
| policy_entropy     | 2.8448212     |
| policy_loss        | -0.0013157168 |
| serial_timesteps   | 1280          |
| time_elapsed       | 2.85          |
| total_timesteps    | 10240         |
| value_loss         | 12.650661     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00017636747 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -12.5         |
| explained_variance | 0.0236        |
| fps                | 3862          |
| n_updates          | 11            |
| policy_entropy     | 2.85034       |
| policy_loss        | -3.351523e-05 |
| serial_timesteps   | 1408          |
| time_elapsed       | 3.59          |
| total_timesteps    | 11264         |
| value_loss         | 12.229746     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00012404434  |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -13.2          |
| explained_variance | -0.0145        |
| fps                | 3735           |
| n_updates          | 12             |
| policy_entropy     | 2.8509202      |
| policy_loss        | -0.00039650477 |
| serial_timesteps   | 1536           |
| time_elapsed       | 3.86           |
| total_timesteps    | 12288          |
| value_loss         | 10.268574      |
---------------------------------------
---------------------------------------
| approxkl           | 6.5575565e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -13.5          |
| explained_variance | 0.0135         |
| fps                | 3791           |
| n_updates          | 13             |
| policy_entropy     | 2.8502991      |
| policy_loss        | -0.00028632698 |
| serial_timesteps   | 1664           |
| time_elapsed       | 4.13           |
| total_timesteps    | 13312          |
| value_loss         | 9.196222       |
---------------------------------------
--------------------------------------
| approxkl           | 9.545379e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -13.5         |
| explained_variance | -0.00231      |
| fps                | 3455          |
| n_updates          | 14            |
| policy_entropy     | 2.8491457     |
| policy_loss        | -0.0009924582 |
| serial_timesteps   | 1792          |
| time_elapsed       | 4.4           |
| total_timesteps    | 14336         |
| value_loss         | 13.212497     |
--------------------------------------
---------------------------------------
| approxkl           | 0.000643676    |
| clipfrac           | 0.00048828125  |
| ep_len_mean        | 150            |
| ep_reward_mean     | -14            |
| explained_variance | 0.0147         |
| fps                | 3846           |
| n_updates          | 15             |
| policy_entropy     | 2.851584       |
| policy_loss        | -0.00076579367 |
| serial_timesteps   | 1920           |
| time_elapsed       | 4.7            |
| total_timesteps    | 15360          |
| value_loss         | 10.549326      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00036634976 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -14           |
| explained_variance | -0.0395       |
| fps                | 3820          |
| n_updates          | 16            |
| policy_entropy     | 2.853098      |
| policy_loss        | -0.0006351884 |
| serial_timesteps   | 2048          |
| time_elapsed       | 4.97          |
| total_timesteps    | 16384         |
| value_loss         | 7.951419      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00018148431 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -14.2         |
| explained_variance | 0.00945       |
| fps                | 3765          |
| n_updates          | 17            |
| policy_entropy     | 2.8511276     |
| policy_loss        | -0.0007805732 |
| serial_timesteps   | 2176          |
| time_elapsed       | 5.24          |
| total_timesteps    | 17408         |
| value_loss         | 12.678104     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00038392172 |
| clipfrac           | 0.00048828125 |
| ep_len_mean        | 150           |
| ep_reward_mean     | -13.8         |
| explained_variance | 0.00371       |
| fps                | 3842          |
| n_updates          | 18            |
| policy_entropy     | 2.8500943     |
| policy_loss        | -0.0018650852 |
| serial_timesteps   | 2304          |
| time_elapsed       | 5.51          |
| total_timesteps    | 18432         |
| value_loss         | 10.722853     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0007443873 |
| clipfrac           | 0.0041503906 |
| ep_len_mean        | 150          |
| ep_reward_mean     | -14.5        |
| explained_variance | 0.014        |
| fps                | 3687         |
| n_updates          | 19           |
| policy_entropy     | 2.851146     |
| policy_loss        | -0.002367881 |
| serial_timesteps   | 2432         |
| time_elapsed       | 5.77         |
| total_timesteps    | 19456        |
| value_loss         | 11.937422    |
-------------------------------------
Eval num_timesteps=20000, episode_reward=1.02 +/- 7.44
Episode length: 150.00 +/- 0.00
New best mean reward!
--------------------------------------
| approxkl           | 0.00048618176 |
| clipfrac           | 0.00048828125 |
| ep_len_mean        | 150           |
| ep_reward_mean     | -14.2         |
| explained_variance | -0.0066       |
| fps                | 1483          |
| n_updates          | 20            |
| policy_entropy     | 2.8546245     |
| policy_loss        | -0.0017798253 |
| serial_timesteps   | 2560          |
| time_elapsed       | 6.05          |
| total_timesteps    | 20480         |
| value_loss         | 13.504738     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00019560906 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -14.2         |
| explained_variance | 0.0148        |
| fps                | 3805          |
| n_updates          | 21            |
| policy_entropy     | 2.8570187     |
| policy_loss        | -0.0008002072 |
| serial_timesteps   | 2688          |
| time_elapsed       | 6.74          |
| total_timesteps    | 21504         |
| value_loss         | 10.176328     |
--------------------------------------
-------------------------------------
| approxkl           | 0.002542291  |
| clipfrac           | 0.02709961   |
| ep_len_mean        | 150          |
| ep_reward_mean     | -14          |
| explained_variance | 0.0157       |
| fps                | 3646         |
| n_updates          | 22           |
| policy_entropy     | 2.8589928    |
| policy_loss        | -0.002752571 |
| serial_timesteps   | 2816         |
| time_elapsed       | 7.01         |
| total_timesteps    | 22528        |
| value_loss         | 9.126867     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0001632889  |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -14           |
| explained_variance | -0.0139       |
| fps                | 3830          |
| n_updates          | 23            |
| policy_entropy     | 2.859353      |
| policy_loss        | -0.0008538824 |
| serial_timesteps   | 2944          |
| time_elapsed       | 7.29          |
| total_timesteps    | 23552         |
| value_loss         | 7.1179867     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0014702317  |
| clipfrac           | 0.009033203   |
| ep_len_mean        | 150           |
| ep_reward_mean     | -13.2         |
| explained_variance | 0.0105        |
| fps                | 3829          |
| n_updates          | 24            |
| policy_entropy     | 2.8587987     |
| policy_loss        | -0.0016715853 |
| serial_timesteps   | 3072          |
| time_elapsed       | 7.56          |
| total_timesteps    | 24576         |
| value_loss         | 10.096928     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0003634623  |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -12.9         |
| explained_variance | -0.0341       |
| fps                | 3861          |
| n_updates          | 25            |
| policy_entropy     | 2.858424      |
| policy_loss        | -0.0009503945 |
| serial_timesteps   | 3200          |
| time_elapsed       | 7.83          |
| total_timesteps    | 25600         |
| value_loss         | 9.8393545     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00041336077 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -12.6         |
| explained_variance | 0.0977        |
| fps                | 3779          |
| n_updates          | 26            |
| policy_entropy     | 2.8575568     |
| policy_loss        | -0.0011002307 |
| serial_timesteps   | 3328          |
| time_elapsed       | 8.09          |
| total_timesteps    | 26624         |
| value_loss         | 4.584229      |
--------------------------------------
-------------------------------------
| approxkl           | 0.002635566  |
| clipfrac           | 0.025390625  |
| ep_len_mean        | 150          |
| ep_reward_mean     | -11.9        |
| explained_variance | -0.000288    |
| fps                | 3753         |
| n_updates          | 27           |
| policy_entropy     | 2.8574898    |
| policy_loss        | -0.004885019 |
| serial_timesteps   | 3456         |
| time_elapsed       | 8.36         |
| total_timesteps    | 27648        |
| value_loss         | 12.759675    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00015926216 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.9         |
| explained_variance | -0.0309       |
| fps                | 3799          |
| n_updates          | 28            |
| policy_entropy     | 2.857642      |
| policy_loss        | -0.0004853155 |
| serial_timesteps   | 3584          |
| time_elapsed       | 8.64          |
| total_timesteps    | 28672         |
| value_loss         | 10.327667     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0004855304  |
| clipfrac           | 0.00048828125 |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.6         |
| explained_variance | 0.0299        |
| fps                | 3845          |
| n_updates          | 29            |
| policy_entropy     | 2.8573418     |
| policy_loss        | -0.0016080885 |
| serial_timesteps   | 3712          |
| time_elapsed       | 8.91          |
| total_timesteps    | 29696         |
| value_loss         | 10.991936     |
--------------------------------------
Eval num_timesteps=30000, episode_reward=-8.91 +/- 7.80
Episode length: 150.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0005945218  |
| clipfrac           | 0.0017089844  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.8         |
| explained_variance | -0.0564       |
| fps                | 1437          |
| n_updates          | 30            |
| policy_entropy     | 2.8575172     |
| policy_loss        | -0.0019432408 |
| serial_timesteps   | 3840          |
| time_elapsed       | 9.17          |
| total_timesteps    | 30720         |
| value_loss         | 10.84626      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0045228526  |
| clipfrac           | 0.056152344   |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.9         |
| explained_variance | 0.0423        |
| fps                | 3789          |
| n_updates          | 31            |
| policy_entropy     | 2.858218      |
| policy_loss        | -0.0038923034 |
| serial_timesteps   | 3968          |
| time_elapsed       | 9.89          |
| total_timesteps    | 31744         |
| value_loss         | 4.209848      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0006501617  |
| clipfrac           | 0.00024414062 |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.9         |
| explained_variance | 0.0595        |
| fps                | 3741          |
| n_updates          | 32            |
| policy_entropy     | 2.8583455     |
| policy_loss        | -0.0011166232 |
| serial_timesteps   | 4096          |
| time_elapsed       | 10.2          |
| total_timesteps    | 32768         |
| value_loss         | 6.0112667     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00043883699 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.6         |
| explained_variance | 0.00212       |
| fps                | 3376          |
| n_updates          | 33            |
| policy_entropy     | 2.858598      |
| policy_loss        | -0.0006781011 |
| serial_timesteps   | 4224          |
| time_elapsed       | 10.4          |
| total_timesteps    | 33792         |
| value_loss         | 4.3623347     |
--------------------------------------
---------------------------------------
| approxkl           | 0.0002046198   |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -10.9          |
| explained_variance | 0.0419         |
| fps                | 3876           |
| n_updates          | 34             |
| policy_entropy     | 2.8580124      |
| policy_loss        | -0.00013532152 |
| serial_timesteps   | 4352           |
| time_elapsed       | 10.7           |
| total_timesteps    | 34816          |
| value_loss         | 3.4098847      |
---------------------------------------
---------------------------------------
| approxkl           | 0.00014264297  |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -10.9          |
| explained_variance | -0.0666        |
| fps                | 3801           |
| n_updates          | 35             |
| policy_entropy     | 2.858954       |
| policy_loss        | -0.00069577334 |
| serial_timesteps   | 4480           |
| time_elapsed       | 11             |
| total_timesteps    | 35840          |
| value_loss         | 4.5939918      |
---------------------------------------
--------------------------------------
| approxkl           | 0.0015572842  |
| clipfrac           | 0.012207031   |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.8         |
| explained_variance | -0.0679       |
| fps                | 3694          |
| n_updates          | 36            |
| policy_entropy     | 2.860852      |
| policy_loss        | -0.0019057224 |
| serial_timesteps   | 4608          |
| time_elapsed       | 11.3          |
| total_timesteps    | 36864         |
| value_loss         | 3.0849242     |
--------------------------------------
---------------------------------------
| approxkl           | 0.0003865994   |
| clipfrac           | 0.00048828125  |
| ep_len_mean        | 150            |
| ep_reward_mean     | -10.8          |
| explained_variance | 0.01           |
| fps                | 3771           |
| n_updates          | 37             |
| policy_entropy     | 2.8622704      |
| policy_loss        | -0.00046262142 |
| serial_timesteps   | 4736           |
| time_elapsed       | 11.5           |
| total_timesteps    | 37888          |
| value_loss         | 3.7322018      |
---------------------------------------
--------------------------------------
| approxkl           | 0.000564706   |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11           |
| explained_variance | 0.00849       |
| fps                | 3739          |
| n_updates          | 38            |
| policy_entropy     | 2.8655584     |
| policy_loss        | -0.0017009701 |
| serial_timesteps   | 4864          |
| time_elapsed       | 11.8          |
| total_timesteps    | 38912         |
| value_loss         | 3.6861684     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0020961834  |
| clipfrac           | 0.025634766   |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.7         |
| explained_variance | 0.00749       |
| fps                | 3761          |
| n_updates          | 39            |
| policy_entropy     | 2.8673048     |
| policy_loss        | -0.0037509564 |
| serial_timesteps   | 4992          |
| time_elapsed       | 12.1          |
| total_timesteps    | 39936         |
| value_loss         | 7.8188615     |
--------------------------------------
Eval num_timesteps=40000, episode_reward=-2.49 +/- 9.45
Episode length: 150.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0008971704  |
| clipfrac           | 0.0026855469  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.3         |
| explained_variance | -0.051        |
| fps                | 1459          |
| n_updates          | 40            |
| policy_entropy     | 2.8677938     |
| policy_loss        | -0.0012710495 |
| serial_timesteps   | 5120          |
| time_elapsed       | 12.4          |
| total_timesteps    | 40960         |
| value_loss         | 4.31338       |
--------------------------------------
--------------------------------------
| approxkl           | 0.00044348976 |
| clipfrac           | 0.00024414062 |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.3         |
| explained_variance | 0.0559        |
| fps                | 3829          |
| n_updates          | 41            |
| policy_entropy     | 2.8688278     |
| policy_loss        | -0.0013695376 |
| serial_timesteps   | 5248          |
| time_elapsed       | 13.1          |
| total_timesteps    | 41984         |
| value_loss         | 3.4596796     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0002743954  |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.4         |
| explained_variance | 0.00667       |
| fps                | 3706          |
| n_updates          | 42            |
| policy_entropy     | 2.8689086     |
| policy_loss        | -4.527578e-05 |
| serial_timesteps   | 5376          |
| time_elapsed       | 13.3          |
| total_timesteps    | 43008         |
| value_loss         | 3.8453386     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0012083353  |
| clipfrac           | 0.010009766   |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.2         |
| explained_variance | 0.0186        |
| fps                | 3619          |
| n_updates          | 43            |
| policy_entropy     | 2.8683875     |
| policy_loss        | -0.0036790525 |
| serial_timesteps   | 5504          |
| time_elapsed       | 13.6          |
| total_timesteps    | 44032         |
| value_loss         | 5.265126      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0005098862  |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.3         |
| explained_variance | 0.00636       |
| fps                | 3614          |
| n_updates          | 44            |
| policy_entropy     | 2.8691914     |
| policy_loss        | -0.0014780285 |
| serial_timesteps   | 5632          |
| time_elapsed       | 13.9          |
| total_timesteps    | 45056         |
| value_loss         | 2.499336      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0012217227  |
| clipfrac           | 0.0048828125  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -9.96         |
| explained_variance | 0.0433        |
| fps                | 3783          |
| n_updates          | 45            |
| policy_entropy     | 2.8682842     |
| policy_loss        | -0.0024297817 |
| serial_timesteps   | 5760          |
| time_elapsed       | 14.2          |
| total_timesteps    | 46080         |
| value_loss         | 2.1202285     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0011992698 |
| clipfrac           | 0.0048828125 |
| ep_len_mean        | 150          |
| ep_reward_mean     | -10.5        |
| explained_variance | -0.0518      |
| fps                | 3608         |
| n_updates          | 46           |
| policy_entropy     | 2.8678932    |
| policy_loss        | -0.002906038 |
| serial_timesteps   | 5888         |
| time_elapsed       | 14.4         |
| total_timesteps    | 47104        |
| value_loss         | 3.597124     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0007725717 |
| clipfrac           | 0.0021972656 |
| ep_len_mean        | 150          |
| ep_reward_mean     | -10.9        |
| explained_variance | -0.012       |
| fps                | 3705         |
| n_updates          | 47           |
| policy_entropy     | 2.8680003    |
| policy_loss        | -0.001583097 |
| serial_timesteps   | 6016         |
| time_elapsed       | 14.7         |
| total_timesteps    | 48128        |
| value_loss         | 4.4360447    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0011102817  |
| clipfrac           | 0.0053710938  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.9         |
| explained_variance | 0.0716        |
| fps                | 3644          |
| n_updates          | 48            |
| policy_entropy     | 2.8659596     |
| policy_loss        | -0.0023601595 |
| serial_timesteps   | 6144          |
| time_elapsed       | 15            |
| total_timesteps    | 49152         |
| value_loss         | 1.2862449     |
--------------------------------------
Eval num_timesteps=50000, episode_reward=3.91 +/- 9.93
Episode length: 150.00 +/- 0.00
New best mean reward!
--------------------------------------
| approxkl           | 0.00048185943 |
| clipfrac           | 0.00024414062 |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11           |
| explained_variance | 0.0154        |
| fps                | 1486          |
| n_updates          | 49            |
| policy_entropy     | 2.86217       |
| policy_loss        | -0.0011241772 |
| serial_timesteps   | 6272          |
| time_elapsed       | 15.3          |
| total_timesteps    | 50176         |
| value_loss         | 2.7555833     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00010285817  |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -11            |
| explained_variance | -0.00124       |
| fps                | 3750           |
| n_updates          | 50             |
| policy_entropy     | 2.8584204      |
| policy_loss        | -0.00011969262 |
| serial_timesteps   | 6400           |
| time_elapsed       | 16             |
| total_timesteps    | 51200          |
| value_loss         | 2.224396       |
---------------------------------------
--------------------------------------
| approxkl           | 0.00028788345 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.3         |
| explained_variance | 0.0512        |
| fps                | 3743          |
| n_updates          | 51            |
| policy_entropy     | 2.8591635     |
| policy_loss        | -0.0007555754 |
| serial_timesteps   | 6528          |
| time_elapsed       | 16.3          |
| total_timesteps    | 52224         |
| value_loss         | 5.295015      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0001689912  |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.4         |
| explained_variance | 0.0171        |
| fps                | 3794          |
| n_updates          | 52            |
| policy_entropy     | 2.859277      |
| policy_loss        | -0.0006476845 |
| serial_timesteps   | 6656          |
| time_elapsed       | 16.5          |
| total_timesteps    | 53248         |
| value_loss         | 6.4177523     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00020804428  |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -10.8          |
| explained_variance | -0.00824       |
| fps                | 3787           |
| n_updates          | 53             |
| policy_entropy     | 2.857098       |
| policy_loss        | -0.00069574534 |
| serial_timesteps   | 6784           |
| time_elapsed       | 16.8           |
| total_timesteps    | 54272          |
| value_loss         | 4.353238       |
---------------------------------------
---------------------------------------
| approxkl           | 0.00015741706  |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -10.8          |
| explained_variance | -0.119         |
| fps                | 3795           |
| n_updates          | 54             |
| policy_entropy     | 2.8551948      |
| policy_loss        | -0.00025036844 |
| serial_timesteps   | 6912           |
| time_elapsed       | 17.1           |
| total_timesteps    | 55296          |
| value_loss         | 2.913791       |
---------------------------------------
--------------------------------------
| approxkl           | 0.00049288647 |
| clipfrac           | 0.0014648438  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.8         |
| explained_variance | 0.0458        |
| fps                | 3835          |
| n_updates          | 55            |
| policy_entropy     | 2.8550794     |
| policy_loss        | -0.00216392   |
| serial_timesteps   | 7040          |
| time_elapsed       | 17.3          |
| total_timesteps    | 56320         |
| value_loss         | 2.62783       |
--------------------------------------
--------------------------------------
| approxkl           | 0.0007536327  |
| clipfrac           | 0.0024414062  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.9         |
| explained_variance | 0.0207        |
| fps                | 3708          |
| n_updates          | 56            |
| policy_entropy     | 2.8581352     |
| policy_loss        | -0.0034306736 |
| serial_timesteps   | 7168          |
| time_elapsed       | 17.6          |
| total_timesteps    | 57344         |
| value_loss         | 3.3008473     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00045736402  |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -11.2          |
| explained_variance | 0.0719         |
| fps                | 3750           |
| n_updates          | 57             |
| policy_entropy     | 2.8627737      |
| policy_loss        | -0.00042844424 |
| serial_timesteps   | 7296           |
| time_elapsed       | 17.9           |
| total_timesteps    | 58368          |
| value_loss         | 3.504998       |
---------------------------------------
--------------------------------------
| approxkl           | 0.001132845   |
| clipfrac           | 0.0056152344  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11.4         |
| explained_variance | 0.0443        |
| fps                | 3727          |
| n_updates          | 58            |
| policy_entropy     | 2.8668978     |
| policy_loss        | -0.0031293759 |
| serial_timesteps   | 7424          |
| time_elapsed       | 18.2          |
| total_timesteps    | 59392         |
| value_loss         | 4.704774      |
--------------------------------------
Eval num_timesteps=60000, episode_reward=-5.74 +/- 5.87
Episode length: 150.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0008530973  |
| clipfrac           | 0.0041503906  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.9         |
| explained_variance | 0.0792        |
| fps                | 1473          |
| n_updates          | 59            |
| policy_entropy     | 2.868683      |
| policy_loss        | -0.0010216619 |
| serial_timesteps   | 7552          |
| time_elapsed       | 18.4          |
| total_timesteps    | 60416         |
| value_loss         | 3.5075097     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0009255414 |
| clipfrac           | 0.0036621094 |
| ep_len_mean        | 150          |
| ep_reward_mean     | -10.4        |
| explained_variance | 0.0822       |
| fps                | 3634         |
| n_updates          | 60           |
| policy_entropy     | 2.8688653    |
| policy_loss        | -0.002410234 |
| serial_timesteps   | 7680         |
| time_elapsed       | 19.1         |
| total_timesteps    | 61440        |
| value_loss         | 3.7933362    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0013237991  |
| clipfrac           | 0.011230469   |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.1         |
| explained_variance | 0.106         |
| fps                | 3797          |
| n_updates          | 61            |
| policy_entropy     | 2.8676815     |
| policy_loss        | -0.0010609098 |
| serial_timesteps   | 7808          |
| time_elapsed       | 19.4          |
| total_timesteps    | 62464         |
| value_loss         | 1.603681      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0011585676  |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.1         |
| explained_variance | -0.00714      |
| fps                | 3783          |
| n_updates          | 62            |
| policy_entropy     | 2.8653538     |
| policy_loss        | -0.0011540275 |
| serial_timesteps   | 7936          |
| time_elapsed       | 19.7          |
| total_timesteps    | 63488         |
| value_loss         | 1.1104249     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0009182269  |
| clipfrac           | 0.0029296875  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -9.88         |
| explained_variance | 0.00684       |
| fps                | 3675          |
| n_updates          | 63            |
| policy_entropy     | 2.8656893     |
| policy_loss        | -0.0014457939 |
| serial_timesteps   | 8064          |
| time_elapsed       | 19.9          |
| total_timesteps    | 64512         |
| value_loss         | 5.900623      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0011166094 |
| clipfrac           | 0.0021972656 |
| ep_len_mean        | 150          |
| ep_reward_mean     | -10.3        |
| explained_variance | 0.0611       |
| fps                | 3684         |
| n_updates          | 64           |
| policy_entropy     | 2.8675127    |
| policy_loss        | -0.002505325 |
| serial_timesteps   | 8192         |
| time_elapsed       | 20.2         |
| total_timesteps    | 65536        |
| value_loss         | 4.8318663    |
-------------------------------------
---------------------------------------
| approxkl           | 0.00022169201  |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -10.4          |
| explained_variance | 0.0871         |
| fps                | 3751           |
| n_updates          | 65             |
| policy_entropy     | 2.8678985      |
| policy_loss        | -5.5579992e-05 |
| serial_timesteps   | 8320           |
| time_elapsed       | 20.5           |
| total_timesteps    | 66560          |
| value_loss         | 3.6254365      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00044548447 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.1         |
| explained_variance | 0.0827        |
| fps                | 3709          |
| n_updates          | 66            |
| policy_entropy     | 2.8678305     |
| policy_loss        | -0.0019472026 |
| serial_timesteps   | 8448          |
| time_elapsed       | 20.8          |
| total_timesteps    | 67584         |
| value_loss         | 4.598458      |
--------------------------------------
---------------------------------------
| approxkl           | 0.00011505056  |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -9.94          |
| explained_variance | 0.00728        |
| fps                | 3595           |
| n_updates          | 67             |
| policy_entropy     | 2.86734        |
| policy_loss        | -0.00036269316 |
| serial_timesteps   | 8576           |
| time_elapsed       | 21.1           |
| total_timesteps    | 68608          |
| value_loss         | 4.551681       |
---------------------------------------
--------------------------------------
| approxkl           | 0.00080517115 |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 150           |
| ep_reward_mean     | -9.64         |
| explained_variance | -0.0238       |
| fps                | 3814          |
| n_updates          | 68            |
| policy_entropy     | 2.868958      |
| policy_loss        | -0.0028248064 |
| serial_timesteps   | 8704          |
| time_elapsed       | 21.3          |
| total_timesteps    | 69632         |
| value_loss         | 1.4523971     |
--------------------------------------
Eval num_timesteps=70000, episode_reward=7.22 +/- 4.65
Episode length: 150.00 +/- 0.00
New best mean reward!
--------------------------------------
| approxkl           | 0.0024242788  |
| clipfrac           | 0.016601562   |
| ep_len_mean        | 150           |
| ep_reward_mean     | -9.64         |
| explained_variance | 0.0705        |
| fps                | 1473          |
| n_updates          | 69            |
| policy_entropy     | 2.8692017     |
| policy_loss        | -0.0019218809 |
| serial_timesteps   | 8832          |
| time_elapsed       | 21.6          |
| total_timesteps    | 70656         |
| value_loss         | 2.9975185     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00018478543  |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -9.56          |
| explained_variance | 0.0857         |
| fps                | 3734           |
| n_updates          | 70             |
| policy_entropy     | 2.8690643      |
| policy_loss        | -0.00013387136 |
| serial_timesteps   | 8960           |
| time_elapsed       | 22.3           |
| total_timesteps    | 71680          |
| value_loss         | 2.1635234      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00013259068 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -9.47         |
| explained_variance | 0.0655        |
| fps                | 3751          |
| n_updates          | 71            |
| policy_entropy     | 2.8688812     |
| policy_loss        | 0.00015205838 |
| serial_timesteps   | 9088          |
| time_elapsed       | 22.6          |
| total_timesteps    | 72704         |
| value_loss         | 2.4880738     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00048846146 |
| clipfrac           | 0.00024414062 |
| ep_len_mean        | 150           |
| ep_reward_mean     | -9.98         |
| explained_variance | 0.118         |
| fps                | 3751          |
| n_updates          | 72            |
| policy_entropy     | 2.870356      |
| policy_loss        | -0.0014875226 |
| serial_timesteps   | 9216          |
| time_elapsed       | 22.8          |
| total_timesteps    | 73728         |
| value_loss         | 4.6407337     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00017457598  |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -9.4           |
| explained_variance | -2.5e-06       |
| fps                | 3772           |
| n_updates          | 73             |
| policy_entropy     | 2.871596       |
| policy_loss        | -0.00062772573 |
| serial_timesteps   | 9344           |
| time_elapsed       | 23.1           |
| total_timesteps    | 74752          |
| value_loss         | 3.7818558      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00076121354 |
| clipfrac           | 0.0026855469  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -9.62         |
| explained_variance | 0.106         |
| fps                | 3678          |
| n_updates          | 74            |
| policy_entropy     | 2.8733547     |
| policy_loss        | -0.0016189924 |
| serial_timesteps   | 9472          |
| time_elapsed       | 23.4          |
| total_timesteps    | 75776         |
| value_loss         | 3.548133      |
--------------------------------------
---------------------------------------
| approxkl           | 0.000998531    |
| clipfrac           | 0.00390625     |
| ep_len_mean        | 150            |
| ep_reward_mean     | -9.38          |
| explained_variance | -0.0252        |
| fps                | 3763           |
| n_updates          | 75             |
| policy_entropy     | 2.8738284      |
| policy_loss        | -0.00075932173 |
| serial_timesteps   | 9600           |
| time_elapsed       | 23.7           |
| total_timesteps    | 76800          |
| value_loss         | 2.106489       |
---------------------------------------
--------------------------------------
| approxkl           | 0.001095469   |
| clipfrac           | 0.0073242188  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -9.38         |
| explained_variance | 0.000957      |
| fps                | 3754          |
| n_updates          | 76            |
| policy_entropy     | 2.8714182     |
| policy_loss        | -0.0023490875 |
| serial_timesteps   | 9728          |
| time_elapsed       | 23.9          |
| total_timesteps    | 77824         |
| value_loss         | 3.331252      |
--------------------------------------
---------------------------------------
| approxkl           | 0.002465121    |
| clipfrac           | 0.024169922    |
| ep_len_mean        | 150            |
| ep_reward_mean     | -9.25          |
| explained_variance | -0.0777        |
| fps                | 3780           |
| n_updates          | 77             |
| policy_entropy     | 2.8704438      |
| policy_loss        | -0.00066495273 |
| serial_timesteps   | 9856           |
| time_elapsed       | 24.2           |
| total_timesteps    | 78848          |
| value_loss         | 2.1762285      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0023250275 |
| clipfrac           | 0.022949219  |
| ep_len_mean        | 150          |
| ep_reward_mean     | -9.17        |
| explained_variance | 0.123        |
| fps                | 3711         |
| n_updates          | 78           |
| policy_entropy     | 2.8727381    |
| policy_loss        | -0.002083221 |
| serial_timesteps   | 9984         |
| time_elapsed       | 24.5         |
| total_timesteps    | 79872        |
| value_loss         | 2.1824312    |
-------------------------------------
Eval num_timesteps=80000, episode_reward=-2.37 +/- 15.54
Episode length: 150.00 +/- 0.00
--------------------------------------
| approxkl           | 0.00046124324 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -8.96         |
| explained_variance | 0.0274        |
| fps                | 1510          |
| n_updates          | 79            |
| policy_entropy     | 2.8744757     |
| policy_loss        | -0.0010538191 |
| serial_timesteps   | 10112         |
| time_elapsed       | 24.8          |
| total_timesteps    | 80896         |
| value_loss         | 3.6709485     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00029760355 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -9.32         |
| explained_variance | 0.0773        |
| fps                | 3832          |
| n_updates          | 80            |
| policy_entropy     | 2.8734808     |
| policy_loss        | -0.0014649912 |
| serial_timesteps   | 10240         |
| time_elapsed       | 25.4          |
| total_timesteps    | 81920         |
| value_loss         | 3.9607863     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00045900396 |
| clipfrac           | 0.00024414062 |
| ep_len_mean        | 150           |
| ep_reward_mean     | -8.48         |
| explained_variance | 0.0857        |
| fps                | 3444          |
| n_updates          | 81            |
| policy_entropy     | 2.8723037     |
| policy_loss        | -0.0010732042 |
| serial_timesteps   | 10368         |
| time_elapsed       | 25.7          |
| total_timesteps    | 82944         |
| value_loss         | 1.4699174     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0013769274  |
| clipfrac           | 0.0036621094  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -8.48         |
| explained_variance | -0.0383       |
| fps                | 3780          |
| n_updates          | 82            |
| policy_entropy     | 2.8737574     |
| policy_loss        | 0.00014658674 |
| serial_timesteps   | 10496         |
| time_elapsed       | 26            |
| total_timesteps    | 83968         |
| value_loss         | 0.9397366     |
--------------------------------------
---------------------------------------
| approxkl           | 6.830707e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -9.04          |
| explained_variance | 0.0209         |
| fps                | 3750           |
| n_updates          | 83             |
| policy_entropy     | 2.8743753      |
| policy_loss        | -0.00029664213 |
| serial_timesteps   | 10624          |
| time_elapsed       | 26.3           |
| total_timesteps    | 84992          |
| value_loss         | 2.8379982      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00014153868 |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -9.19         |
| explained_variance | 0.164         |
| fps                | 3703          |
| n_updates          | 84            |
| policy_entropy     | 2.8737073     |
| policy_loss        | -0.0016517907 |
| serial_timesteps   | 10752         |
| time_elapsed       | 26.6          |
| total_timesteps    | 86016         |
| value_loss         | 3.0267692     |
--------------------------------------
--------------------------------------
| approxkl           | 9.907161e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 150           |
| ep_reward_mean     | -9.21         |
| explained_variance | 0.0603        |
| fps                | 3769          |
| n_updates          | 85            |
| policy_entropy     | 2.8739457     |
| policy_loss        | 2.8965063e-05 |
| serial_timesteps   | 10880         |
| time_elapsed       | 26.8          |
| total_timesteps    | 87040         |
| value_loss         | 3.2213402     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00045041397 |
| clipfrac           | 0.00048828125 |
| ep_len_mean        | 150           |
| ep_reward_mean     | -8.87         |
| explained_variance | 0.0126        |
| fps                | 3791          |
| n_updates          | 86            |
| policy_entropy     | 2.8768032     |
| policy_loss        | -0.0012329445 |
| serial_timesteps   | 11008         |
| time_elapsed       | 27.1          |
| total_timesteps    | 88064         |
| value_loss         | 3.3033564     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0035686358 |
| clipfrac           | 0.041992188  |
| ep_len_mean        | 150          |
| ep_reward_mean     | -9.1         |
| explained_variance | 0.0182       |
| fps                | 3765         |
| n_updates          | 87           |
| policy_entropy     | 2.878562     |
| policy_loss        | -0.002187017 |
| serial_timesteps   | 11136        |
| time_elapsed       | 27.4         |
| total_timesteps    | 89088        |
| value_loss         | 3.96513      |
-------------------------------------
Eval num_timesteps=90000, episode_reward=6.53 +/- 6.16
Episode length: 150.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0030496488 |
| clipfrac           | 0.031982422  |
| ep_len_mean        | 150          |
| ep_reward_mean     | -10.3        |
| explained_variance | 0.219        |
| fps                | 1433         |
| n_updates          | 88           |
| policy_entropy     | 2.8780475    |
| policy_loss        | -0.003021354 |
| serial_timesteps   | 11264        |
| time_elapsed       | 27.6         |
| total_timesteps    | 90112        |
| value_loss         | 1.5307875    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0010108802 |
| clipfrac           | 0.0041503906 |
| ep_len_mean        | 150          |
| ep_reward_mean     | -10.3        |
| explained_variance | 0.279        |
| fps                | 3815         |
| n_updates          | 89           |
| policy_entropy     | 2.8765688    |
| policy_loss        | -0.001908069 |
| serial_timesteps   | 11392        |
| time_elapsed       | 28.4         |
| total_timesteps    | 91136        |
| value_loss         | 0.95776445   |
-------------------------------------
---------------------------------------
| approxkl           | 0.00029679984  |
| clipfrac           | 0.0            |
| ep_len_mean        | 150            |
| ep_reward_mean     | -10.3          |
| explained_variance | 0.0157         |
| fps                | 3740           |
| n_updates          | 90             |
| policy_entropy     | 2.8761303      |
| policy_loss        | -0.00076218834 |
| serial_timesteps   | 11520          |
| time_elapsed       | 28.6           |
| total_timesteps    | 92160          |
| value_loss         | 1.9133308      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00033275527 |
| clipfrac           | 0.00024414062 |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.5         |
| explained_variance | 0.0749        |
| fps                | 3709          |
| n_updates          | 91            |
| policy_entropy     | 2.8749077     |
| policy_loss        | -0.0008284697 |
| serial_timesteps   | 11648         |
| time_elapsed       | 28.9          |
| total_timesteps    | 93184         |
| value_loss         | 3.0113657     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0013404355  |
| clipfrac           | 0.0078125     |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.7         |
| explained_variance | 0.0777        |
| fps                | 3684          |
| n_updates          | 92            |
| policy_entropy     | 2.8754404     |
| policy_loss        | -0.0015958855 |
| serial_timesteps   | 11776         |
| time_elapsed       | 29.2          |
| total_timesteps    | 94208         |
| value_loss         | 3.1996007     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0037764115 |
| clipfrac           | 0.04663086   |
| ep_len_mean        | 150          |
| ep_reward_mean     | -10.2        |
| explained_variance | 0.0213       |
| fps                | 3682         |
| n_updates          | 93           |
| policy_entropy     | 2.8776047    |
| policy_loss        | -0.003499212 |
| serial_timesteps   | 11904        |
| time_elapsed       | 29.5         |
| total_timesteps    | 95232        |
| value_loss         | 2.0403962    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0010877043  |
| clipfrac           | 0.0053710938  |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.6         |
| explained_variance | -0.0408       |
| fps                | 3784          |
| n_updates          | 94            |
| policy_entropy     | 2.8812718     |
| policy_loss        | -0.0023598177 |
| serial_timesteps   | 12032         |
| time_elapsed       | 29.7          |
| total_timesteps    | 96256         |
| value_loss         | 2.600089      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0034226873 |
| clipfrac           | 0.041992188  |
| ep_len_mean        | 150          |
| ep_reward_mean     | -11          |
| explained_variance | 0.0401       |
| fps                | 3738         |
| n_updates          | 95           |
| policy_entropy     | 2.8805206    |
| policy_loss        | -0.004427407 |
| serial_timesteps   | 12160        |
| time_elapsed       | 30           |
| total_timesteps    | 97280        |
| value_loss         | 1.6838175    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0017733438  |
| clipfrac           | 0.012451172   |
| ep_len_mean        | 150           |
| ep_reward_mean     | -11           |
| explained_variance | 0.122         |
| fps                | 3821          |
| n_updates          | 96            |
| policy_entropy     | 2.8820658     |
| policy_loss        | -0.0016715634 |
| serial_timesteps   | 12288         |
| time_elapsed       | 30.3          |
| total_timesteps    | 98304         |
| value_loss         | 0.83710545    |
--------------------------------------
--------------------------------------
| approxkl           | 0.0033604463  |
| clipfrac           | 0.029052734   |
| ep_len_mean        | 150           |
| ep_reward_mean     | -10.6         |
| explained_variance | 0.00873       |
| fps                | 3759          |
| n_updates          | 97            |
| policy_entropy     | 2.882579      |
| policy_loss        | -0.0033645388 |
| serial_timesteps   | 12416         |
| time_elapsed       | 30.5          |
| total_timesteps    | 99328         |
| value_loss         | 2.4898272     |
--------------------------------------
Saving to logs/train_0.1M_Reacher2Dof-v0/ppo2/Reacher2Dof-v0_2
pybullet build time: Sep  9 2020 17:03:46
