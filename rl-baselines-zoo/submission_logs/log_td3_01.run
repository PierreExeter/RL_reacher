WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

========== Reacher2Dof-v0 ==========
Seed: 1
OrderedDict([('n_timesteps', 1000000.0), ('policy', 'MlpPolicy')])
Using 1 environments
Overwriting n_timesteps with n=10000
Creating test environment
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:131: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/policies.py:124: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:164: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:194: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:209: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:226: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:237: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:240: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

Log path: logs/train_10K_Reacher2Dof-v0/td3/Reacher2Dof-v0_2
/home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/callbacks.py:287: UserWarning: Training and eval env are not of the same type<stable_baselines.common.base_class._UnvecWrapper object at 0x7f71db140240> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f71db145f28>
  "{} != {}".format(self.training_env, self.eval_env))
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -27.7     |
| episodes                | 4         |
| eplenmean               | 150       |
| fps                     | 522       |
| mean 100 episode reward | -27.7     |
| n_updates               | 500       |
| qf1_loss                | 1.4161147 |
| qf2_loss                | 1.4990212 |
| success rate            | 0         |
| time_elapsed            | 1         |
| total timesteps         | 600       |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -43       |
| episodes                | 8         |
| eplenmean               | 150       |
| fps                     | 540       |
| mean 100 episode reward | -43       |
| n_updates               | 1100      |
| qf1_loss                | 12.517265 |
| qf2_loss                | 12.561588 |
| success rate            | 0         |
| time_elapsed            | 2         |
| total timesteps         | 1200      |
---------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ep_rewmean              | -34.5      |
| episodes                | 12         |
| eplenmean               | 150        |
| fps                     | 546        |
| mean 100 episode reward | -34.5      |
| n_updates               | 1700       |
| qf1_loss                | 10.4142275 |
| qf2_loss                | 10.494449  |
| success rate            | 0          |
| time_elapsed            | 3          |
| total timesteps         | 1800       |
----------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -29.1     |
| episodes                | 16        |
| eplenmean               | 150       |
| fps                     | 550       |
| mean 100 episode reward | -29.1     |
| n_updates               | 2300      |
| qf1_loss                | 7.3496985 |
| qf2_loss                | 7.453394  |
| success rate            | 0         |
| time_elapsed            | 4         |
| total timesteps         | 2400      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -26.2     |
| episodes                | 20        |
| eplenmean               | 150       |
| fps                     | 552       |
| mean 100 episode reward | -26.2     |
| n_updates               | 2900      |
| qf1_loss                | 6.4511733 |
| qf2_loss                | 6.568796  |
| success rate            | 0         |
| time_elapsed            | 5         |
| total timesteps         | 3000      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -21.4     |
| episodes                | 24        |
| eplenmean               | 150       |
| fps                     | 553       |
| mean 100 episode reward | -21.4     |
| n_updates               | 3500      |
| qf1_loss                | 5.331386  |
| qf2_loss                | 5.4164443 |
| success rate            | 0         |
| time_elapsed            | 6         |
| total timesteps         | 3600      |
---------------------------------------
--------------------------------------
| current_lr              | 0.0003   |
| ep_rewmean              | -20.1    |
| episodes                | 28       |
| eplenmean               | 150      |
| fps                     | 555      |
| mean 100 episode reward | -20.1    |
| n_updates               | 4100     |
| qf1_loss                | 4.521104 |
| qf2_loss                | 4.569865 |
| success rate            | 0        |
| time_elapsed            | 7        |
| total timesteps         | 4200     |
--------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -18.2     |
| episodes                | 32        |
| eplenmean               | 150       |
| fps                     | 556       |
| mean 100 episode reward | -18.2     |
| n_updates               | 4700      |
| qf1_loss                | 4.1614895 |
| qf2_loss                | 4.205371  |
| success rate            | 0         |
| time_elapsed            | 8         |
| total timesteps         | 4800      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -17.7     |
| episodes                | 36        |
| eplenmean               | 150       |
| fps                     | 558       |
| mean 100 episode reward | -17.7     |
| n_updates               | 5300      |
| qf1_loss                | 3.474482  |
| qf2_loss                | 3.5475214 |
| success rate            | 0         |
| time_elapsed            | 9         |
| total timesteps         | 5400      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -16.4     |
| episodes                | 40        |
| eplenmean               | 150       |
| fps                     | 558       |
| mean 100 episode reward | -16.4     |
| n_updates               | 5900      |
| qf1_loss                | 3.3365257 |
| qf2_loss                | 3.4004889 |
| success rate            | 0         |
| time_elapsed            | 10        |
| total timesteps         | 6000      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -16.2     |
| episodes                | 44        |
| eplenmean               | 150       |
| fps                     | 559       |
| mean 100 episode reward | -16.2     |
| n_updates               | 6500      |
| qf1_loss                | 2.9892516 |
| qf2_loss                | 2.9788122 |
| success rate            | 0         |
| time_elapsed            | 11        |
| total timesteps         | 6600      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -16.4     |
| episodes                | 48        |
| eplenmean               | 150       |
| fps                     | 558       |
| mean 100 episode reward | -16.4     |
| n_updates               | 7100      |
| qf1_loss                | 3.099491  |
| qf2_loss                | 2.9954827 |
| success rate            | 0         |
| time_elapsed            | 12        |
| total timesteps         | 7200      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -15.1     |
| episodes                | 52        |
| eplenmean               | 150       |
| fps                     | 559       |
| mean 100 episode reward | -15.1     |
| n_updates               | 7700      |
| qf1_loss                | 2.764017  |
| qf2_loss                | 2.8199775 |
| success rate            | 0         |
| time_elapsed            | 13        |
| total timesteps         | 7800      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -13.9     |
| episodes                | 56        |
| eplenmean               | 150       |
| fps                     | 559       |
| mean 100 episode reward | -13.9     |
| n_updates               | 8300      |
| qf1_loss                | 2.673026  |
| qf2_loss                | 2.6717267 |
| success rate            | 0         |
| time_elapsed            | 15        |
| total timesteps         | 8400      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -13.2     |
| episodes                | 60        |
| eplenmean               | 150       |
| fps                     | 557       |
| mean 100 episode reward | -13.2     |
| n_updates               | 8900      |
| qf1_loss                | 2.3377733 |
| qf2_loss                | 2.364366  |
| success rate            | 0         |
| time_elapsed            | 16        |
| total timesteps         | 9000      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -12.5     |
| episodes                | 64        |
| eplenmean               | 150       |
| fps                     | 556       |
| mean 100 episode reward | -12.5     |
| n_updates               | 9500      |
| qf1_loss                | 2.6719    |
| qf2_loss                | 2.6188703 |
| success rate            | 0         |
| time_elapsed            | 17        |
| total timesteps         | 9600      |
---------------------------------------
Eval num_timesteps=10000, episode_reward=-12.01 +/- 6.23
Episode length: 150.00 +/- 0.00
New best mean reward!
Saving to logs/train_10K_Reacher2Dof-v0/td3/Reacher2Dof-v0_2
pybullet build time: Sep  9 2020 17:03:46
