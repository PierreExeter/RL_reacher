WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

========== Reacher2Dof-v0 ==========
Seed: 1
OrderedDict([('n_envs', 8),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
Overwriting n_timesteps with n=100000
Creating test environment
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/distributions.py:418: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:181: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:99: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:298: The name tf.diag is deprecated. Please use tf.linalg.tensor_diag instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:546: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:548: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:221: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:223: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

Log path: logs/train_0.1M_Reacher2Dof-v0/acktr/Reacher2Dof-v0_2
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:306: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:307: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:973: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:914: The name tf.mod is deprecated. Please use tf.math.mod instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:621: The name tf.self_adjoint_eig is deprecated. Please use tf.linalg.eigh instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:319: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.

---------------------------------
| explained_variance | 0.00427  |
| fps                | 185      |
| nupdates           | 1        |
| policy_entropy     | 2.84     |
| policy_loss        | -0.146   |
| total_timesteps    | 160      |
| value_loss         | 40.9     |
---------------------------------
Eval num_timesteps=10000, episode_reward=-4.07 +/- 10.16
Episode length: 150.00 +/- 0.00
New best mean reward!
---------------------------------
| ep_len_mean        | 150      |
| ep_reward_mean     | -13.3    |
| explained_variance | 0.0578   |
| fps                | 2541     |
| nupdates           | 100      |
| policy_entropy     | 2.85     |
| policy_loss        | -0.0211  |
| total_timesteps    | 16000    |
| value_loss         | 54       |
---------------------------------
Eval num_timesteps=20000, episode_reward=2.04 +/- 6.51
Episode length: 150.00 +/- 0.00
New best mean reward!
Eval num_timesteps=30000, episode_reward=-7.32 +/- 6.48
Episode length: 150.00 +/- 0.00
---------------------------------
| ep_len_mean        | 150      |
| ep_reward_mean     | -10.2    |
| explained_variance | -0.148   |
| fps                | 2619     |
| nupdates           | 200      |
| policy_entropy     | 2.86     |
| policy_loss        | -0.0275  |
| total_timesteps    | 32000    |
| value_loss         | 22.6     |
---------------------------------
Eval num_timesteps=40000, episode_reward=-4.93 +/- 8.37
Episode length: 150.00 +/- 0.00
---------------------------------
| ep_len_mean        | 150      |
| ep_reward_mean     | -10.9    |
| explained_variance | -0.129   |
| fps                | 2708     |
| nupdates           | 300      |
| policy_entropy     | 2.87     |
| policy_loss        | 0.0181   |
| total_timesteps    | 48000    |
| value_loss         | 6.73     |
---------------------------------
Eval num_timesteps=50000, episode_reward=1.41 +/- 9.52
Episode length: 150.00 +/- 0.00
Eval num_timesteps=60000, episode_reward=-7.30 +/- 5.26
Episode length: 150.00 +/- 0.00
---------------------------------
| ep_len_mean        | 150      |
| ep_reward_mean     | -9.51    |
| explained_variance | 0.222    |
| fps                | 2694     |
| nupdates           | 400      |
| policy_entropy     | 2.85     |
| policy_loss        | -0.0319  |
| total_timesteps    | 64000    |
| value_loss         | 1.62     |
---------------------------------
Eval num_timesteps=70000, episode_reward=3.35 +/- 4.21
Episode length: 150.00 +/- 0.00
New best mean reward!
Eval num_timesteps=80000, episode_reward=-26.69 +/- 34.72
Episode length: 150.00 +/- 0.00
---------------------------------
| ep_len_mean        | 150      |
| ep_reward_mean     | -19.3    |
| explained_variance | 0.18     |
| fps                | 2686     |
| nupdates           | 500      |
| policy_entropy     | 2.86     |
| policy_loss        | -0.0511  |
| total_timesteps    | 80000    |
| value_loss         | 84.3     |
---------------------------------
Eval num_timesteps=90000, episode_reward=-7.77 +/- 19.85
Episode length: 150.00 +/- 0.00
---------------------------------
| ep_len_mean        | 150      |
| ep_reward_mean     | -28.6    |
| explained_variance | 0.342    |
| fps                | 2723     |
| nupdates           | 600      |
| policy_entropy     | 2.86     |
| policy_loss        | -0.123   |
| total_timesteps    | 96000    |
| value_loss         | 42.1     |
---------------------------------
Eval num_timesteps=100000, episode_reward=-17.77 +/- 12.37
Episode length: 150.00 +/- 0.00
Saving to logs/train_0.1M_Reacher2Dof-v0/acktr/Reacher2Dof-v0_2
pybullet build time: Sep  9 2020 17:03:46
