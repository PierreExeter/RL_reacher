WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

========== Reacher2Dof-v0 ==========
Seed: 0
OrderedDict([('n_timesteps', 1000000.0), ('policy', 'MlpPolicy')])
Using 1 environments
Overwriting n_timesteps with n=10000
Creating test environment
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:131: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/policies.py:124: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:164: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:194: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:209: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:226: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:237: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:240: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

Log path: logs/train_10K_Reacher2Dof-v0/td3/Reacher2Dof-v0_1
/home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/callbacks.py:287: UserWarning: Training and eval env are not of the same type<stable_baselines.common.base_class._UnvecWrapper object at 0x7fcc843ee2e8> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fcc843eec50>
  "{} != {}".format(self.training_env, self.eval_env))
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -36.4     |
| episodes                | 4         |
| eplenmean               | 150       |
| fps                     | 532       |
| mean 100 episode reward | -36.4     |
| n_updates               | 500       |
| qf1_loss                | 18.953482 |
| qf2_loss                | 18.563663 |
| success rate            | 0         |
| time_elapsed            | 1         |
| total timesteps         | 600       |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -84.9     |
| episodes                | 8         |
| eplenmean               | 150       |
| fps                     | 560       |
| mean 100 episode reward | -84.9     |
| n_updates               | 1100      |
| qf1_loss                | 43.751358 |
| qf2_loss                | 44.06456  |
| success rate            | 0         |
| time_elapsed            | 2         |
| total timesteps         | 1200      |
---------------------------------------
--------------------------------------
| current_lr              | 0.0003   |
| ep_rewmean              | -93.9    |
| episodes                | 12       |
| eplenmean               | 150      |
| fps                     | 567      |
| mean 100 episode reward | -93.9    |
| n_updates               | 1700     |
| qf1_loss                | 55.47902 |
| qf2_loss                | 55.48483 |
| success rate            | 0        |
| time_elapsed            | 3        |
| total timesteps         | 1800     |
--------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -87.2     |
| episodes                | 16        |
| eplenmean               | 150       |
| fps                     | 572       |
| mean 100 episode reward | -87.2     |
| n_updates               | 2300      |
| qf1_loss                | 47.812042 |
| qf2_loss                | 47.608524 |
| success rate            | 0         |
| time_elapsed            | 4         |
| total timesteps         | 2400      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -69.3     |
| episodes                | 20        |
| eplenmean               | 150       |
| fps                     | 574       |
| mean 100 episode reward | -69.3     |
| n_updates               | 2900      |
| qf1_loss                | 37.61429  |
| qf2_loss                | 37.440617 |
| success rate            | 0         |
| time_elapsed            | 5         |
| total timesteps         | 3000      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -58.3     |
| episodes                | 24        |
| eplenmean               | 150       |
| fps                     | 575       |
| mean 100 episode reward | -58.3     |
| n_updates               | 3500      |
| qf1_loss                | 31.43322  |
| qf2_loss                | 31.237835 |
| success rate            | 0         |
| time_elapsed            | 6         |
| total timesteps         | 3600      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -50.7     |
| episodes                | 28        |
| eplenmean               | 150       |
| fps                     | 575       |
| mean 100 episode reward | -50.7     |
| n_updates               | 4100      |
| qf1_loss                | 26.700796 |
| qf2_loss                | 26.58061  |
| success rate            | 0         |
| time_elapsed            | 7         |
| total timesteps         | 4200      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -46.3     |
| episodes                | 32        |
| eplenmean               | 150       |
| fps                     | 574       |
| mean 100 episode reward | -46.3     |
| n_updates               | 4700      |
| qf1_loss                | 23.458427 |
| qf2_loss                | 23.358974 |
| success rate            | 0         |
| time_elapsed            | 8         |
| total timesteps         | 4800      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -41.3     |
| episodes                | 36        |
| eplenmean               | 150       |
| fps                     | 574       |
| mean 100 episode reward | -41.3     |
| n_updates               | 5300      |
| qf1_loss                | 21.696074 |
| qf2_loss                | 21.586697 |
| success rate            | 0         |
| time_elapsed            | 9         |
| total timesteps         | 5400      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -37.9     |
| episodes                | 40        |
| eplenmean               | 150       |
| fps                     | 575       |
| mean 100 episode reward | -37.9     |
| n_updates               | 5900      |
| qf1_loss                | 20.581955 |
| qf2_loss                | 20.431368 |
| success rate            | 0         |
| time_elapsed            | 10        |
| total timesteps         | 6000      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -35       |
| episodes                | 44        |
| eplenmean               | 150       |
| fps                     | 576       |
| mean 100 episode reward | -35       |
| n_updates               | 6500      |
| qf1_loss                | 18.313833 |
| qf2_loss                | 18.213213 |
| success rate            | 0         |
| time_elapsed            | 11        |
| total timesteps         | 6600      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -33.6     |
| episodes                | 48        |
| eplenmean               | 150       |
| fps                     | 576       |
| mean 100 episode reward | -33.6     |
| n_updates               | 7100      |
| qf1_loss                | 15.38071  |
| qf2_loss                | 15.359994 |
| success rate            | 0         |
| time_elapsed            | 12        |
| total timesteps         | 7200      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -31.5     |
| episodes                | 52        |
| eplenmean               | 150       |
| fps                     | 575       |
| mean 100 episode reward | -31.5     |
| n_updates               | 7700      |
| qf1_loss                | 13.869568 |
| qf2_loss                | 13.752328 |
| success rate            | 0         |
| time_elapsed            | 13        |
| total timesteps         | 7800      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -29.1     |
| episodes                | 56        |
| eplenmean               | 150       |
| fps                     | 575       |
| mean 100 episode reward | -29.1     |
| n_updates               | 8300      |
| qf1_loss                | 14.413164 |
| qf2_loss                | 14.199399 |
| success rate            | 0         |
| time_elapsed            | 14        |
| total timesteps         | 8400      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -27.8     |
| episodes                | 60        |
| eplenmean               | 150       |
| fps                     | 576       |
| mean 100 episode reward | -27.8     |
| n_updates               | 8900      |
| qf1_loss                | 11.844949 |
| qf2_loss                | 11.673853 |
| success rate            | 0         |
| time_elapsed            | 15        |
| total timesteps         | 9000      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -26.6     |
| episodes                | 64        |
| eplenmean               | 150       |
| fps                     | 576       |
| mean 100 episode reward | -26.6     |
| n_updates               | 9500      |
| qf1_loss                | 13.029475 |
| qf2_loss                | 12.692336 |
| success rate            | 0         |
| time_elapsed            | 16        |
| total timesteps         | 9600      |
---------------------------------------
Eval num_timesteps=10000, episode_reward=-34.53 +/- 13.68
Episode length: 150.00 +/- 0.00
New best mean reward!
Saving to logs/train_10K_Reacher2Dof-v0/td3/Reacher2Dof-v0_1
pybullet build time: Sep  9 2020 17:03:46
