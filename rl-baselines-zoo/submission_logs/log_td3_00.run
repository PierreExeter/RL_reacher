WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

========== Reacher2Dof-v0 ==========
Seed: 0
OrderedDict([('n_timesteps', 1000000.0), ('policy', 'MlpPolicy')])
Using 1 environments
Overwriting n_timesteps with n=10000
Creating test environment
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:131: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/policies.py:124: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:164: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:194: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:209: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:226: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:237: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/td3/td3.py:240: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

Log path: logs/train_10K_Reacher2Dof-v0/td3/Reacher2Dof-v0_1
/home/pierre/bin/anaconda3/envs/reacher_link/lib/python3.7/site-packages/stable_baselines/common/callbacks.py:287: UserWarning: Training and eval env are not of the same type<stable_baselines.common.base_class._UnvecWrapper object at 0x7f336740b390> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f336740bd30>
  "{} != {}".format(self.training_env, self.eval_env))
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -31.3     |
| episodes                | 4         |
| eplenmean               | 150       |
| fps                     | 508       |
| mean 100 episode reward | -31.3     |
| n_updates               | 500       |
| qf1_loss                | 6.8281703 |
| qf2_loss                | 7.053559  |
| success rate            | 0         |
| time_elapsed            | 1         |
| total timesteps         | 600       |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -22       |
| episodes                | 8         |
| eplenmean               | 150       |
| fps                     | 528       |
| mean 100 episode reward | -22       |
| n_updates               | 1100      |
| qf1_loss                | 3.8796227 |
| qf2_loss                | 3.9556262 |
| success rate            | 0         |
| time_elapsed            | 2         |
| total timesteps         | 1200      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -19.3     |
| episodes                | 12        |
| eplenmean               | 150       |
| fps                     | 537       |
| mean 100 episode reward | -19.3     |
| n_updates               | 1700      |
| qf1_loss                | 3.1405618 |
| qf2_loss                | 3.1053643 |
| success rate            | 0         |
| time_elapsed            | 3         |
| total timesteps         | 1800      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -23.3     |
| episodes                | 16        |
| eplenmean               | 150       |
| fps                     | 537       |
| mean 100 episode reward | -23.3     |
| n_updates               | 2300      |
| qf1_loss                | 5.0517707 |
| qf2_loss                | 5.0285215 |
| success rate            | 0         |
| time_elapsed            | 4         |
| total timesteps         | 2400      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -38.4     |
| episodes                | 20        |
| eplenmean               | 150       |
| fps                     | 541       |
| mean 100 episode reward | -38.4     |
| n_updates               | 2900      |
| qf1_loss                | 10.515386 |
| qf2_loss                | 10.976689 |
| success rate            | 0         |
| time_elapsed            | 5         |
| total timesteps         | 3000      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -36.3     |
| episodes                | 24        |
| eplenmean               | 150       |
| fps                     | 531       |
| mean 100 episode reward | -36.3     |
| n_updates               | 3500      |
| qf1_loss                | 10.290131 |
| qf2_loss                | 10.77049  |
| success rate            | 0         |
| time_elapsed            | 6         |
| total timesteps         | 3600      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -30.5     |
| episodes                | 28        |
| eplenmean               | 150       |
| fps                     | 526       |
| mean 100 episode reward | -30.5     |
| n_updates               | 4100      |
| qf1_loss                | 8.229175  |
| qf2_loss                | 8.4910755 |
| success rate            | 0         |
| time_elapsed            | 7         |
| total timesteps         | 4200      |
---------------------------------------
--------------------------------------
| current_lr              | 0.0003   |
| ep_rewmean              | -27.7    |
| episodes                | 32       |
| eplenmean               | 150      |
| fps                     | 528      |
| mean 100 episode reward | -27.7    |
| n_updates               | 4700     |
| qf1_loss                | 7.487304 |
| qf2_loss                | 7.825049 |
| success rate            | 0        |
| time_elapsed            | 9        |
| total timesteps         | 4800     |
--------------------------------------
--------------------------------------
| current_lr              | 0.0003   |
| ep_rewmean              | -29.5    |
| episodes                | 36       |
| eplenmean               | 150      |
| fps                     | 530      |
| mean 100 episode reward | -29.5    |
| n_updates               | 5300     |
| qf1_loss                | 8.673966 |
| qf2_loss                | 8.902313 |
| success rate            | 0        |
| time_elapsed            | 10       |
| total timesteps         | 5400     |
--------------------------------------
--------------------------------------
| current_lr              | 0.0003   |
| ep_rewmean              | -27.9    |
| episodes                | 40       |
| eplenmean               | 150      |
| fps                     | 531      |
| mean 100 episode reward | -27.9    |
| n_updates               | 5900     |
| qf1_loss                | 8.200179 |
| qf2_loss                | 8.394009 |
| success rate            | 0        |
| time_elapsed            | 11       |
| total timesteps         | 6000     |
--------------------------------------
--------------------------------------
| current_lr              | 0.0003   |
| ep_rewmean              | -25.3    |
| episodes                | 44       |
| eplenmean               | 150      |
| fps                     | 532      |
| mean 100 episode reward | -25.3    |
| n_updates               | 6500     |
| qf1_loss                | 8.021372 |
| qf2_loss                | 8.132032 |
| success rate            | 0        |
| time_elapsed            | 12       |
| total timesteps         | 6600     |
--------------------------------------
--------------------------------------
| current_lr              | 0.0003   |
| ep_rewmean              | -24.5    |
| episodes                | 48       |
| eplenmean               | 150      |
| fps                     | 534      |
| mean 100 episode reward | -24.5    |
| n_updates               | 7100     |
| qf1_loss                | 8.454421 |
| qf2_loss                | 8.279745 |
| success rate            | 0        |
| time_elapsed            | 13       |
| total timesteps         | 7200     |
--------------------------------------
--------------------------------------
| current_lr              | 0.0003   |
| ep_rewmean              | -22.6    |
| episodes                | 52       |
| eplenmean               | 150      |
| fps                     | 533      |
| mean 100 episode reward | -22.6    |
| n_updates               | 7700     |
| qf1_loss                | 7.710508 |
| qf2_loss                | 7.613948 |
| success rate            | 0        |
| time_elapsed            | 14       |
| total timesteps         | 7800     |
--------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -20.6     |
| episodes                | 56        |
| eplenmean               | 150       |
| fps                     | 531       |
| mean 100 episode reward | -20.6     |
| n_updates               | 8300      |
| qf1_loss                | 6.353871  |
| qf2_loss                | 6.2281666 |
| success rate            | 0         |
| time_elapsed            | 15        |
| total timesteps         | 8400      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -19.6     |
| episodes                | 60        |
| eplenmean               | 150       |
| fps                     | 531       |
| mean 100 episode reward | -19.6     |
| n_updates               | 8900      |
| qf1_loss                | 5.8256917 |
| qf2_loss                | 5.673273  |
| success rate            | 0         |
| time_elapsed            | 16        |
| total timesteps         | 9000      |
---------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ep_rewmean              | -19       |
| episodes                | 64        |
| eplenmean               | 150       |
| fps                     | 531       |
| mean 100 episode reward | -19       |
| n_updates               | 9500      |
| qf1_loss                | 6.478272  |
| qf2_loss                | 6.2523017 |
| success rate            | 0         |
| time_elapsed            | 18        |
| total timesteps         | 9600      |
---------------------------------------
Eval num_timesteps=10000, episode_reward=-4.68 +/- 8.73
Episode length: 150.00 +/- 0.00
New best mean reward!
Saving to logs/train_10K_Reacher2Dof-v0/td3/Reacher2Dof-v0_1
pybullet build time: Sep  9 2020 17:03:46
